{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Project Task: </H1>\n",
    "The aim of the project is to predict the failure of HAGC System having 21 indicators in next 48 hours.\n",
    "\n",
    "Inorder to solve the problem I have implemented two methods to apply:\n",
    "\n",
    "<b> 1) Anamoly Detection </b>\n",
    "\n",
    "<b> 2) Supervised Machine Learning Methods </b>\n",
    "\n",
    "Four files were given, and the file with indicator reaadings has been chose to apply the above methods as the file has indicator readings and prospective features.\n",
    "\n",
    "<b> Data Description </b>\n",
    "\n",
    "Data consists of Four Files: 1) File 1: Contains  Downtimes (This includes both prevenetive & Corrective maintenanace records) 2) File 2: Contains the Data from  February 2011 to Febrauary 2013 3) File 3 consists of maintenaace data and works comments. 4) File 4 consists of the descriptions of the Asset and its indicators.\n",
    "\n",
    "\n",
    "<b> Data Cleaning: </b>\n",
    "\n",
    "1) All the three files are have been Filtered to get the data only for asset \"544-630\".\n",
    "\n",
    "2) Columns with Time stamp in all the files have been seperated as two columns, i.e. Date and Time. This is done to concatenate Files based on the Dates. Why should we concatenate using date will be expalined in the approach section.\n",
    "\n",
    "3) Columns with redundant data and constant varaince have been removed in order to reduce the number of dimensions.\n",
    "\n",
    "4) Indicator Reading Column has been cleaned to get retreive only numbers.\n",
    "\n",
    "<b> Approach </b>\n",
    "\n",
    "<b> 1) Anamoly Detection: </b>\n",
    "\n",
    "For the given problem, the aim is to predict if the machine fails. It is clearly understood that, the given data is unlabelled, Anamoly Detection comes into picture at such situations.\n",
    "\n",
    "Anomaly Detection is the problem of finding patterns in data that do not conform to a model of “normal” behavior. It helps to detect abnormal behavior which can be an indication of systems failure , and they need to be able to trigger the appropriate steps towards taking corrective actions. In each case, it is important to characterize what is normal, what is deviant or anomalous and how significant is the anomaly. It is necessary to characterize the normal state of the system by observing data about the system over a period of time when the system is deemed normal by observers and users of that system, and to use this characterization as a baseline to flag anomalous behavior.\n",
    "\n",
    "Relating this to our problem, we need to detect the abnormal readings that help us to learn when the system would fail over a period of time.\n",
    "\n",
    "<b> Why should we apply only Anamolus detection and not any other Supervised Machine Learning Algorithm? </b>\n",
    "\n",
    "The reason we have applied this because, when the data is convereted into Logitudinal form and observed the machine failure time, there were very less number of anamolies i.e. negative samples (machine failure)  comapred to postivie samples (normal behaviour of the machine). Hence, It is easy to train a model on the positive samples and then predict the negative Data.\n",
    "\n",
    "<b> Steps followed to implement Anamoly Detection </b>\n",
    "\n",
    "<b> Feature Engineering: </b>\n",
    "\n",
    "\n",
    "1) We have 21 indicators for the asset given and not all the indicators  with abnormal behaviour have been lead to downtime. If only rest indicators  are monitored, then downtime Costs can be reduced. It has been observed that 10 out of 21 indicators have a prominenet abnormal behaviour which has led to downtime. Hence the data for only these indiactors has been used to preedict the failure.\n",
    "\n",
    "2) Along with the indicator reading we have also have othere features the help to predict the failure like:\n",
    "\n",
    "->'Indicator State Name': Tells the state of the indicator reading. This feature has been considered  because this helps to understed the if the reading is an anamoly.\n",
    "\n",
    "-> 'Alarm Type Name': Tells Type of the Alarm, i.e if its critical/warning or low alarm. This reeading along with other tells if an alarm is given for a partiular indicator reading.\n",
    "\n",
    "->'Fixed During Inspection': Boolean Feature, tells if the indicator is fixed or not. This feature has been taken beacuse, if the indicator is fixed many a times and other indicators are not then this may lead to failure of the machine.\n",
    "\n",
    "-> 'Acknowledgement Status': If the reading has to be acknowleged or not. Even during the alaram few reading aree monitored, hence such behaviour can also lead to downtime if the indicator isnt replaced.\n",
    "\n",
    "-> 'Acknowledgement Method': if it has to be acknowleged, how it has been done? \n",
    "\n",
    "Pattern in the above features also helps us predict the anamolies in the data. \n",
    "\n",
    "3) Separation of Data into positive and negative samples. The Data is separated into postive samples by remving the negative samples. the negative samples are retreived from the logitudibal data by joining the data with downtime samples on date.Not all the downtime samples are used as they consist of prevetive maiantenence data as well. Only Downtime samples with emergency and corrective as the work type have been separated and joined. Total number of postive samples were 1331 and negative samples were 11. These 11 samples aree used as test data and 1331 samples as train data.\n",
    "\n",
    "<b> One Class Svm - Approach </b>\n",
    "\n",
    "4) The Anamoly detection is done by training the data on One class SVM and since we have may features i.e 80 features which are correlated (observed from the correaltion matrix), prinicipal component analysis is applied to reduce the number of features and gain more accuracy. One Class SVM is trained on pca object (postive samples)  and is made to predict the pac object of negative samples.\n",
    "\n",
    "5) This method has achieved an Accuracy of 86%.\n",
    "\n",
    "<b> 2) Supervised Learning Method: </b>\n",
    "\n",
    "Data cleaning and feature engineering is same except for the approach. In this approach, we have created a Y varaible which is binary. The value Y will be one even if one of the INdidicator's Acknowlged status is monitoring / Acknowledged implying the downtime else Y is 0.\n",
    "\n",
    "The data has been split ito 70 to 30 ratio and Models like Logistice Regression , Adaboost, SVM and Random Forest have been trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Python Code <b>\n",
    "\n",
    "1) Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 2) Read the Data from the Given csv's and retreive the data for asset - \"544-630\" </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read all the three Files\n",
    "ind=pd.read_csv('./Steckel Mill Systems Data - Indicator.csv')\n",
    "down=pd.read_csv('./Steckel Mill Systems Data - Downtime.csv')\n",
    "work=pd.read_csv('./Steckel Mill Systems Data - Work Order.csv')\n",
    "work = work[work[u'Asset To Work On']=='544-630']\n",
    "ind = ind[ind[u'Asset Number']=='544-630']\n",
    "down =  down[down[u'ACD Asset Number']=='544-630']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b> 3) Convert the Time stamps to Date and Time and create a new column to add them. This helps to join the downtime data and understand Downtime Readings </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "down[u'Downtime Started'] =pd.DataFrame( down[u'Downtime Started'])\n",
    "down[u'Downtime Started']= pd.to_datetime(down[u'Downtime Started'])\n",
    "down[u'Downtime_Date']= [d.date() for d in down[u'Downtime Started'] ]\n",
    "down[u'Downtime_Time']= [d.time() for d in down[u'Downtime Started'] ]\n",
    "\n",
    "\n",
    "work[u'Requested Completion Date'] =pd.DataFrame( work[u'Requested Completion Date'])\n",
    "work[u'Requested Completion Date']= pd.to_datetime(work[u'Requested Completion Date'])\n",
    "work[u'Requested_Completion_Date']= [d.date() for d in work[u'Requested Completion Date'] ]\n",
    "work[u'Requested_Completion_Time']= [d.time() for d in work[u'Requested Completion Date'] ]\n",
    "\n",
    "\n",
    "ind['Date and Time Collected'] =pd.DataFrame( ind['Date and Time Collected'])\n",
    "ind['Date and Time Collected']= pd.to_datetime(ind['Date and Time Collected'])\n",
    "ind[u'Date and Time Acknowledged']=pd.DataFrame(ind[u'Date and Time Acknowledged'])\n",
    "ind[u'Date and Time Acknowledged']=pd.to_datetime(ind[u'Date and Time Acknowledged'])\n",
    "ind['ind_Coll_Date']= [d.date() for d in ind['Date and Time Collected'] ]\n",
    "ind['ind_Coll_Time']= [d.time() for d in ind['Date and Time Collected'] ]\n",
    "ind['Date_A']= [d.date() for d in ind['Date and Time Collected']]\n",
    "ind['Time_A']= [d.time() for d in ind['Date and Time Collected'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 4) Data Cleaning : Next Three steps remove the columns with redundant data and constant varaince: </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c=['Indicator Name',\n",
    "'Indicator Name UniversalID',\n",
    "'Indicator Reading Object ID',\n",
    "'Indicator State Object ID',\n",
    "'Indicator State UniversalID',\n",
    "'Alarm Type Object ID',\n",
    "'Alarm Type UniversalID',\n",
    "'Date and Time Collected',\n",
    "'Date And Time Uploaded',\n",
    "'Collected By',\n",
    "'Collected By Object ID',\n",
    "'Collected By UniversalID',\n",
    "'Adjustment Value',\n",
    "'UOM',\n",
    "'Life-to-date Value',\n",
    "'UOM',\n",
    "'Reading Status',\n",
    "'Collected on Work Order',\n",
    "'WO Task Collected On Object ID',\n",
    "'WO Task Collected On UniversalID',\n",
    "'WO Task Collected On Title',\n",
    "'Standard Task Number',\n",
    "'Standard Task Object ID',\n",
    "'Standard Task UniversalID',\n",
    "'Checksheet',\n",
    "'Acknowledged By',\n",
    "'Acknowledged By Object ID',\n",
    "'Acknowledged By UniversalID',\n",
    "'Acknowledgement Work Order Task Number',\n",
    "'Acknowledgement Work Order Task Title',\n",
    "'Work Order Task Object ID',\n",
    "'WO Task UniversalID',\n",
    "'Work Type Object ID',\n",
    "'Work Type UniversalID',\n",
    "'Work Classification',\n",
    "'Work Classification Object ID',\n",
    "'Work Classification UniversalID',\n",
    "'Incorrect Reading',\n",
    "'Asset Title',\n",
    "'Asset Object ID',\n",
    "'Asset UniversalID',\n",
    "'Asset Type Name',\n",
    "'Asset Type Object ID',\n",
    "'Asset Type UniversalID']\n",
    "ind.drop(c, axis=1,inplace=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c=['Task',\n",
    "'WO Task Object ID',\n",
    "'WO Task UniversalID',\n",
    "'Closed By',\n",
    "'Work Completion Status Object ID',\n",
    "'Work Completion Status UniversalID',\n",
    "'Asset Object ID',\n",
    "'Asset UniversalID',\n",
    "'Asset Priority',\n",
    "'Asset Type Name',\n",
    "'Asset Type Object ID',\n",
    "'Asset Type UniversalID',\n",
    "'Asset Original In Service Date',\n",
    "'Maintenance Group',\n",
    "'Primary Trade',\n",
    "'Work Type Object ID',\n",
    "'Work Type UniversalID',\n",
    "'Work Classification UniversalID',\n",
    "'Work Classification Object ID',\n",
    "'Created By',\n",
    "'Planner',\n",
    "'Completed By',\n",
    "'Date And Time WO Created',\n",
    "'Last Worker Comments',\n",
    "'Calculate Estimated Duration',\n",
    "'Estimated Duration',\n",
    "'UOM',\n",
    "'Number Of Times Planned Completion Date Changed',\n",
    "'Scheduled Date',\n",
    "'Data Collection Required',\n",
    "'Data Collection Method',\n",
    "'Document Package Created On',\n",
    "'Has Purchase Requirements',\n",
    "'Planned Labor',\n",
    "'Planned Parts (Int/Ext)',\n",
    "'Planned Ext Parts',\n",
    "'Planned Outside Service',\n",
    "'Planned Total Cost',\n",
    "'Std Task Number',\n",
    "'Std Task Object ID',\n",
    "'Std Task UniversalID',\n",
    "'Std Task Title',\n",
    "'Std Task Frequency',\n",
    "'Std Job Trigger Expression',\n",
    "'Std Job Triggering Cycle Rule',\n",
    "'Readings Entered Via An Activity Report']\n",
    "\n",
    "work.drop(c, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c=['ACD Object ID',\n",
    "'ACD UniversalID',\n",
    "'ACD Asset Type Name',\n",
    "'ACD Asset Type Object ID',\n",
    "'ACD Asset Type UniversalID',\n",
    "'UOM',\n",
    "'Scheduled Downtime  Duration',\n",
    "'UOM',\n",
    "'Unscheduled Downtime Duration',\n",
    "'UOM',\n",
    "'Task',\n",
    "'WO Task Object ID',\n",
    "'WO Task UniversalID',\n",
    "'Work Type Object ID',\n",
    "'Work Type UniversalID',\n",
    "'Work Classification Object ID',\n",
    "'Work Classification UniversalID',\n",
    "'WO Task Title',\n",
    "'Week Number',\n",
    "'Downtime Reason',\n",
    "'Downtime Reason Object ID',\n",
    "'Downtime Reason UniversalID',\n",
    "'Downtime Costs (Unscheduled Downtime)',\n",
    "'Downtime Percentage',\n",
    "'Downtime Incident Number']\n",
    "down.drop(c,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 5) Identify the indicators that are most resposible for the downtime. Indicators are identified by using the feature Work Type in Indicator file. It tells if the Downtime was corrective / preventive : </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1625008589, 1625008593, 1625005665, 1625005815, 1625005814,\n",
       "       1625005813, 1625005807, 1625005698, 1625005810, 1625005806], dtype=int64)"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=['Corrective', 'Emergency']\n",
    "actual_ind= ind[ind['Work Type'].isin(l)]#\n",
    "actual_ind['Indicator Object ID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <b> 6) Create new data frames for the 10 indicators retreived above, this helps to create the longitudinal Data </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IH = ['IH1','IH2','IH3','IH4','IH5','IH6','IH7','IH8','IH9','IH10']\n",
    "d = {}\n",
    "imp=[1625008589, 1625008593, 1625005665, 1625005815, 1625005814,1625005813, 1625005807, 1625005698, 1625005810, 1625005806]       \n",
    "\n",
    "for i,j in zip(imp,IH):\n",
    "    d[j] = pd.DataFrame()\n",
    "    d[j] = ind.loc[ind[ 'Indicator Object ID'] == i] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 7) Clean the Indicator columns </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CJCCP0ol10\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\CJCCP0ol10\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\CJCCP0ol10\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\CJCCP0ol10\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\CJCCP0ol10\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\CJCCP0ol10\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "d['IH1']['Indicator Reading'] =   d['IH1']['Indicator Reading'].apply(lambda x : pd.Series(x.split(' g')))\n",
    "d['IH1']['Indicator Reading'] = d['IH1']['Indicator Reading'].str.replace(',', '')\n",
    "d['IH2']['Indicator Reading'] =   d['IH2']['Indicator Reading'].apply(lambda x : pd.Series(x.split(' g')))\n",
    "d['IH2']['Indicator Reading'] = d['IH2']['Indicator Reading'].str.replace(',', '')\n",
    "d['IH3']['Indicator Reading'] =   d['IH3']['Indicator Reading'].apply(lambda x : pd.Series(x.split(' g')))\n",
    "d['IH3']['Indicator Reading'] = d['IH3']['Indicator Reading'].str.replace(',', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>  Feature Engineering </b> \n",
    "\n",
    "<b> 8) Rename the columns the are required for the prediction and drop the rest </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CJCCP0ol10\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "imp=[1625008589, 1625008593, 1625005665, 1625005815, 1625005814,1625005813, 1625005807, 1625005698, 1625005810, 1625005806]       \n",
    "c=['Indicator Object ID','Task','Date and Time Acknowledged','Asset Number','UOM.1',u\"Collector's Note\",\n",
    "   u'ind_Coll_Time', u'Date_A', u'Time_A']\n",
    "for i,j in zip(imp,IH):\n",
    "    d[j].drop(c,axis=1,inplace=True)\n",
    "    d[j] =  d[j].rename(columns={'Indicator Reading': 'Ind_'+str(i),\n",
    "\n",
    "'Indicator State Name':'Indicator State Name_'+str(i) ,'Alarm Type Name': 'Alarm_'+str(i), 'Fixed During Inspection':'FDI_'+str(i)\n",
    "   ,                    'Acknowledgement Status': 'AS_'+str(i),\n",
    "       'Acknowledgement Method': 'AM_'+str(i),\n",
    "       'Acknowledgement Work Order': 'WO_'+str(i), 'Work Type':'WT_'+str(i),\n",
    "       'ind_Coll_Date':'col_Date_'+str(i)})\n",
    "    d[j].set_index(['col_Date_'+str(i)], inplace = True)  \n",
    "    d[j].fillna(0,axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 9) Create the longitudinal data with join all the individual indicator dataframes using index: data collected. This data has 80 features and 1331 rows </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Long =pd.merge(d['IH1'], d['IH2'],  how='outer', left_index=True, right_index=True)\n",
    "Long1 =pd.merge(Long, d['IH3'],  how='outer', left_index=True, right_index=True)\n",
    "Long2 =pd.merge(Long1, d['IH4'],  how='outer', left_index=True, right_index=True)\n",
    "Long3 =pd.merge(Long2, d['IH5'],  how='outer', left_index=True, right_index=True)\n",
    "Long4 =pd.merge(Long3, d['IH6'],  how='outer', left_index=True, right_index=True)\n",
    "Long5 =pd.merge(Long4, d['IH7'],  how='outer', left_index=True, right_index=True)\n",
    "Long6 =pd.merge(Long5, d['IH8'],  how='outer', left_index=True, right_index=True)\n",
    "Long7 =pd.merge(Long6, d['IH9'],  how='outer', left_index=True, right_index=True)\n",
    "Long_Final =pd.merge(Long7, d['IH10'],  how='outer', left_index=True, right_index=True)\n",
    "Long_Final.fillna(0,axis=1,inplace=True)\n",
    "Long_Final.index = pd.to_datetime(Long_Final.index )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 10) Create the psotive and negative samples by seoarating the negative samples with  same downtime Date and Postive samples to samples with no down time date </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l=['Corrective', 'Emergency']\n",
    "actual_down= down[down['Work Type'].isin(l)]#or ind['Work Type'] == 'Emergency'\n",
    "c= actual_down[u'Downtime_Date']\n",
    "Bad_Data = Long_Final[Long_Final.index.isin(c)]\n",
    "Good_Data = Long_Final[~Long_Final.index.isin(c)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b> Postive Data Shape </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1331, 80)"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Good_Data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Negative Data Shape </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 80)"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bad_Data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 11) Labelling the Positive and Negative Samples <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CJCCP0ol10\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\CJCCP0ol10\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "for i  in Good_Data.columns:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    Good_Data[i] =le.fit_transform(Good_Data[i])\n",
    "\n",
    "    \n",
    "    \n",
    "for i  in Bad_Data.columns:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    Bad_Data[i] =le.fit_transform(Bad_Data[i])\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Correlatin between the features and thier elimination using PCA: </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr =Long_Final.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr.to_csv(\"corr.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>  Implementing Approach 1 - ANAMOLY DETECTION USING ONE CLASS SVM </b>\n",
    "\n",
    "<b> 12) Implementation of Principal Component Analysis, this is done to elimate the high correlated features and reduce the dimensionality </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  37.05   57.19   72.98   83.98   91.16   95.21   97.68   99.33   99.99\n",
      "  100.01  100.01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CJCCP0ol10\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\CJCCP0ol10\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15bbadd8>]"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15a2ada0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = np.array(Good_Data)\n",
    "test = np.array(Bad_Data)\n",
    "train = scale(train)\n",
    "test = scale(test)\n",
    "pca = PCA(n_components=11 , whiten=True)\n",
    "pca.fit(train)\n",
    "pca.fit(test)\n",
    "train = pca.transform(train)\n",
    "test = pca.transform(test)\n",
    "#The amount of variance that each PC explains\n",
    "var= pca.explained_variance_ratio_\n",
    "#Cumulative Variance explains\n",
    "var1=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
    "print var1 # Print the  Cumulative:\n",
    "plt.plot(var1) # Print the features!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 13) Fit and Preedict the One Class SVM, the sepate the anamolies </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CJCCP0ol10\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "test = np.array(Bad_Data)\n",
    "test = scale(test)\n",
    "pca.fit(test)\n",
    "test = pca.transform(test)\n",
    "clf = svm.OneClassSVM(kernel='rbf', degree=2, gamma=0.1, coef0=0.0,\n",
    "                    tol=0.001, nu=0.1, shrinking=True, cache_size=200,\n",
    "                    verbose=False, max_iter=-1, random_state=None)\n",
    "clf.fit(train)\n",
    "y_pred_train = clf.predict(train)\n",
    "y_pred_test = clf.predict(test)\n",
    "n_error_train = y_pred_train[y_pred_train == -1].size\n",
    "n_error_test = y_pred_test[y_pred_test == -1].size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 15) Measuring the accuracy of ONE CLASS SVM </b>\n",
    "\n",
    "   <b> The accuracy achieved is 86% <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87002253944402708"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_true = np.ones((1331,1), dtype=np.int)\n",
    "accuracy_score(y_true, y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Approch 2--- SUPERVISED MACHINE LEARNING METHODS </b>\n",
    "\n",
    "<b> 16) Creating the target column based the condition mentioned above </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CJCCP0ol10\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\CJCCP0ol10\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "a=['Acknowledged with work order', 'Fixed during inspection', 'Monitoring']\n",
    "Long_Final['y']=0\n",
    "\n",
    "for i in range(Long_Final.shape[0]):\n",
    "    if (Long_Final['AM_1625008589'][i] in (a) ) or (Long_Final['AM_1625008593'][i] in (a) ) or (Long_Final['AM_1625005665'][i] in (a)) or (Long_Final['AM_1625005815'][i] in (a) ) or (Long_Final['AM_1625005814'][i] in (a) ) or (Long_Final['AM_1625005813'][i] in (a)) or (Long_Final['AM_1625005807'][i] in (a))  or (Long_Final['AM_1625005698'][i] in (a)) or (Long_Final['AM_1625005810'][i] in (a))  or (Long_Final['AM_1625005806'][i] in(a)) :\n",
    "        Long_Final['y'][i]=1\n",
    "    else:\n",
    "        Long_Final['y'][i]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 17) Labelling the Data </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i  in Long_Final.columns:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    Long_Final[i] =le.fit_transform(Long_Final[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 18) Splitting the Train and Test Data </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "train=Long_Final.iloc[:,0:80]\n",
    "Y = Long_Final.iloc[:,-1:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 19) Applying Logistice Regression </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CJCCP0ol10\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pca = PCA(n_components=40)\n",
    "cls = LogisticRegression() \n",
    "\n",
    "#pipe = Pipeline([('pca', pca), ('logistic', clf)])\n",
    "cls.fit(X_train, y_train)\n",
    "predictions = cls.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 20) Calculating the Accuracy of Logistice Regression Model </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99322799097065462"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.DataFrame(predictions)\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Other Supervised Learing Models -- 1) Random Forest Regression </b>\n",
    "\n",
    "<b> The accuracy Obtained is 99%, seems like this mdel is overfitting </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CJCCP0ol10\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Confusion Matrix of : ', array([[205,   0],\n",
      "       [  1, 237]]), ' and its Accuracy: ', 0.99774266365688491)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc=rfc.fit(X_train, y_train)\n",
    "Y_pred= rfc.predict(X_test)\n",
    "print('Confusion Matrix of : ',confusion_matrix(y_test, Y_pred), ' and its Accuracy: ', accuracy_score(y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Other Supervised Learing Models -- 1) Ada Boost Regression </b>\n",
    "\n",
    "<b> The accuracy Obtained is 99%, seems like this mdel is overfitting </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CJCCP0ol10\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Confusion Matrix of : ', array([[205,   0],\n",
      "       [  1, 237]]), ' and its Accuracy: ', 0.99774266365688491)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                         algorithm=\"SAMME\",  n_estimators=200)\n",
    "\n",
    "bdt=bdt.fit(X_train, y_train)\n",
    "Y_pred= bdt.predict(X_test)\n",
    "print('Confusion Matrix of : ',confusion_matrix(y_test, Y_pred), ' and its Accuracy: ', accuracy_score(y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Other Supervised Learing Models -- 1) Random Forest Regression </b>\n",
    "\n",
    "<b> The accuracy Obtained is 93%, seems like this model is better than Random Forest and Adaboost </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Confusion Matrix of : ', array([[177,  28],\n",
      "       [  0, 238]]), ' and its Accuracy: ', 0.93679458239277658)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CJCCP0ol10\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\base.py:514: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, svm\n",
    "kernel_svm = svm.SVC(gamma=.2)\n",
    "kernel_svm=kernel_svm.fit(X_train, y_train)\n",
    "Y_pred= kernel_svm.predict(X_test)\n",
    "print('Confusion Matrix of : ',confusion_matrix(y_test, Y_pred), ' and its Accuracy: ', accuracy_score(y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
